{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aprendizaje por Reforzamiento.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPy8mUQyB627ocWHIONqEKh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kevinGRZ10/freecodecamp-proyectos-youtube/blob/main/Aprendizaje_por_Reforzamiento.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9NHWZehudLj"
      },
      "source": [
        "#Importamos librerias a utilizar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FloZ_D1BwPSF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RMSixg-rzUB"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "from time import sleep\n",
        "from IPython.display import clear_output\n",
        "from math import ceil,floor\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oU40wD4uiyE"
      },
      "source": [
        "#Creamos la clase PongAgent:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ul2ZcPIXr7ac"
      },
      "source": [
        "class PongAgent:\n",
        "    \n",
        "    def __init__(self, game, policy=None, discount_factor = 0.1, learning_rate = 0.1, ratio_explotacion = 0.9):\n",
        "\n",
        "        # Creamos la tabla de politicas\n",
        "        if policy is not None:\n",
        "            self._q_table = policy\n",
        "        else:\n",
        "            position = list(game.positions_space.shape)\n",
        "            position.append(len(game.action_space))\n",
        "            self._q_table = np.zeros(position)\n",
        "        \n",
        "        self.discount_factor = discount_factor\n",
        "        self.learning_rate = learning_rate\n",
        "        self.ratio_explotacion = ratio_explotacion\n",
        "\n",
        "    def get_next_step(self, state, game):\n",
        "        \n",
        "        # Damos un paso aleatorio...\n",
        "        next_step = np.random.choice(list(game.action_space))\n",
        "        \n",
        "        # o tomaremos el mejor paso...\n",
        "        if np.random.uniform() <= self.ratio_explotacion:\n",
        "            # tomar el maximo\n",
        "            idx_action = np.random.choice(np.flatnonzero(\n",
        "                    self._q_table[state[0],state[1],state[2]] == self._q_table[state[0],state[1],state[2]].max()\n",
        "                ))\n",
        "            next_step = list(game.action_space)[idx_action]\n",
        "\n",
        "        return next_step\n",
        "\n",
        "    # actualizamos las politicas con las recompensas obtenidas\n",
        "    def update(self, game, old_state, action_taken, reward_action_taken, new_state, reached_end):\n",
        "        idx_action_taken =list(game.action_space).index(action_taken)\n",
        "\n",
        "        actual_q_value_options = self._q_table[old_state[0], old_state[1], old_state[2]]\n",
        "        actual_q_value = actual_q_value_options[idx_action_taken]\n",
        "\n",
        "        future_q_value_options = self._q_table[new_state[0], new_state[1], new_state[2]]\n",
        "        future_max_q_value = reward_action_taken  +  self.discount_factor*future_q_value_options.max()\n",
        "        if reached_end:\n",
        "            future_max_q_value = reward_action_taken #maximum reward\n",
        "\n",
        "        self._q_table[old_state[0], old_state[1], old_state[2], idx_action_taken] = actual_q_value + \\\n",
        "                                              self.learning_rate*(future_max_q_value -actual_q_value)\n",
        "    \n",
        "    def print_policy(self):\n",
        "        for row in np.round(self._q_table,1):\n",
        "            for column in row:\n",
        "                print('[', end='')\n",
        "                for value in column:\n",
        "                    print(str(value).zfill(5), end=' ')\n",
        "                print('] ', end='')\n",
        "            print('')\n",
        "            \n",
        "    def get_policy(self):\n",
        "        return self._q_table"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SftzhPdIuwsM"
      },
      "source": [
        "#Creamos la clase Ambiente"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9xl1v9csCmR"
      },
      "source": [
        "class PongEnvironment:\n",
        "    \n",
        "    def __init__(self, max_life=3, height_px = 40, width_px = 50, movimiento_px = 3):\n",
        "        \n",
        "        self.action_space = ['Arriba','Abajo']\n",
        "        \n",
        "        self._step_penalization = 0\n",
        "        \n",
        "        self.state = [0,0,0]\n",
        "        \n",
        "        self.total_reward = 0\n",
        "        \n",
        "        self.dx = movimiento_px\n",
        "        self.dy = movimiento_px\n",
        "        \n",
        "        filas = ceil(height_px/movimiento_px)\n",
        "        columnas = ceil(width_px/movimiento_px)\n",
        "        \n",
        "        self.positions_space = np.array([[[0 for z in range(columnas)] \n",
        "                                                  for y in range(filas)] \n",
        "                                                     for x in range(filas)])\n",
        "\n",
        "        self.lives = max_life\n",
        "        self.max_life=max_life\n",
        "        \n",
        "        self.x = randint(int(width_px/2), width_px) \n",
        "        self.y = randint(0, height_px-10)\n",
        "        \n",
        "        self.player_alto = int(height_px/4)\n",
        "\n",
        "        self.player1 = self.player_alto  # posic. inicial del player\n",
        "        \n",
        "        self.score = 0\n",
        "        \n",
        "        self.width_px = width_px\n",
        "        self.height_px = height_px\n",
        "        self.radio = 2.5\n",
        "\n",
        "    def reset(self):\n",
        "        self.total_reward = 0\n",
        "        self.state = [0,0,0]\n",
        "        self.lives = self.max_life\n",
        "        self.score = 0\n",
        "        self.x = randint(int(self.width_px/2), self.width_px) \n",
        "        self.y = randint(0, self.height_px-10)\n",
        "        return self.state\n",
        "\n",
        "    def step(self, action, animate=False):\n",
        "        self._apply_action(action, animate)\n",
        "        done = self.lives <=0 # final\n",
        "        reward = self.score\n",
        "        reward += self._step_penalization\n",
        "        self.total_reward += reward\n",
        "        return self.state, reward , done\n",
        "\n",
        "    def _apply_action(self, action, animate=False):\n",
        "        \n",
        "        if action == \"Arriba\":\n",
        "            self.player1 += abs(self.dy)\n",
        "        elif action == \"Abajo\":\n",
        "            self.player1 -= abs(self.dy)\n",
        "            \n",
        "        self.avanza_player()\n",
        "\n",
        "        self.avanza_frame()\n",
        "\n",
        "        if animate:\n",
        "            clear_output(wait=True);\n",
        "            fig = self.dibujar_frame()\n",
        "            plt.show()\n",
        "\n",
        "        self.state = (floor(self.player1/abs(self.dy))-2, floor(self.y/abs(self.dy))-2, floor(self.x/abs(self.dx))-2)\n",
        "    \n",
        "    def detectaColision(self, ball_y, player_y):\n",
        "        if (player_y+self.player_alto >= (ball_y-self.radio)) and (player_y <= (ball_y+self.radio)):\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "    \n",
        "    def avanza_player(self):\n",
        "        if self.player1 + self.player_alto >= self.height_px:\n",
        "            self.player1 = self.height_px - self.player_alto\n",
        "        elif self.player1 <= -abs(self.dy):\n",
        "            self.player1 = -abs(self.dy)\n",
        "\n",
        "    def avanza_frame(self):\n",
        "        self.x += self.dx\n",
        "        self.y += self.dy\n",
        "        if self.x <= 3 or self.x > self.width_px:\n",
        "            self.dx = -self.dx\n",
        "            if self.x <= 3:\n",
        "                ret = self.detectaColision(self.y, self.player1)\n",
        "\n",
        "                if ret:\n",
        "                    self.score = 10\n",
        "                else:\n",
        "                    self.score = -10\n",
        "                    self.lives -= 1\n",
        "                    if self.lives>0:\n",
        "                        self.x = randint(int(self.width_px/2), self.width_px)\n",
        "                        self.y = randint(0, self.height_px-10)\n",
        "                        self.dx = abs(self.dx)\n",
        "                        self.dy = abs(self.dy)\n",
        "        else:\n",
        "            self.score = 0\n",
        "\n",
        "        if self.y < 0 or self.y > self.height_px:\n",
        "            self.dy = -self.dy\n",
        "\n",
        "    def dibujar_frame(self):\n",
        "        fig = plt.figure(figsize=(5, 4))\n",
        "        a1 = plt.gca()\n",
        "        circle = plt.Circle((self.x, self.y), self.radio, fc='slategray', ec=\"black\")\n",
        "        a1.set_ylim(-5, self.height_px+5)\n",
        "        a1.set_xlim(-5, self.width_px+5)\n",
        "\n",
        "        rectangle = plt.Rectangle((-5, self.player1), 5, self.player_alto, fc='gold', ec=\"none\")\n",
        "        a1.add_patch(circle);\n",
        "        a1.add_patch(rectangle)\n",
        "        #a1.set_yticklabels([]);a1.set_xticklabels([]);\n",
        "        plt.text(4, self.height_px, \"SCORE:\"+str(self.total_reward)+\"  LIFE:\"+str(self.lives), fontsize=12)\n",
        "        if self.lives <=0:\n",
        "            plt.text(10, self.height_px-14, \"GAME OVER\", fontsize=16)\n",
        "        elif self.total_reward >= 1000:\n",
        "            plt.text(10, self.height_px-14, \"YOU WIN!\", fontsize=16)\n",
        "        return fig"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZkW570uvFi9"
      },
      "source": [
        "#Juego"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5O77Qb6ZsHkm"
      },
      "source": [
        "def play(rounds=5000, max_life=3, discount_factor = 0.1, learning_rate = 0.1,\n",
        "         ratio_explotacion=0.9,learner=None, game=None, animate=False):\n",
        "\n",
        "    if game is None:\n",
        "        # si usamos movimiento_px = 5 creamos una tabla de politicas de 8x10\n",
        "        # si usamos movimiento_px = 3 la tabla sera de 14x17\n",
        "        game = PongEnvironment(max_life=max_life, movimiento_px = 3)\n",
        "        \n",
        "    if learner is None:\n",
        "        print(\"Begin new Train!\")\n",
        "        learner = PongAgent(game, discount_factor = discount_factor,learning_rate = learning_rate, ratio_explotacion= ratio_explotacion)\n",
        "\n",
        "    max_points= -9999\n",
        "    first_max_reached = 0\n",
        "    total_rw=0\n",
        "    steps=[]\n",
        "\n",
        "    for played_games in range(0, rounds):\n",
        "        state = game.reset()\n",
        "        reward, done = None, None\n",
        "        \n",
        "        itera=0\n",
        "        while (done != True) and (itera < 3000 and game.total_reward<=1000):\n",
        "            old_state = np.array(state)\n",
        "            next_action = learner.get_next_step(state, game)\n",
        "            state, reward, done = game.step(next_action, animate=animate)\n",
        "            if rounds > 1:\n",
        "                learner.update(game, old_state, next_action, reward, state, done)\n",
        "            itera+=1\n",
        "        \n",
        "        steps.append(itera)\n",
        "        \n",
        "        total_rw+=game.total_reward\n",
        "        if game.total_reward > max_points:\n",
        "            max_points=game.total_reward\n",
        "            first_max_reached = played_games\n",
        "        \n",
        "        if played_games %500==0 and played_games >1 and not animate:\n",
        "            print(\"-- Partidas[\", played_games, \"] Avg.Puntos[\", int(total_rw/played_games),\"]  AVG Steps[\", int(np.array(steps).mean()), \"] Max Score[\", max_points,\"]\")\n",
        "                \n",
        "    if played_games>1:\n",
        "        print('Partidas[',played_games,'] Avg.Puntos[',int(total_rw/played_games),'] Max score[', max_points,'] en partida[',first_max_reached,']')\n",
        "        \n",
        "    #learner.print_policy()\n",
        "    \n",
        "    return learner, game"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61hZPkXBvmXb"
      },
      "source": [
        "#Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbS6cWNesLvB",
        "outputId": "b18efafd-c79e-4cd3-8639-d2fd29b9f041"
      },
      "source": [
        "\n",
        "learner, game = play(rounds=3000, discount_factor = 0.2, learning_rate = 0.1, ratio_explotacion=0.85)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Begin new Train!\n",
            "-- Partidas[ 500 ] Avg.Puntos[ 19 ]  AVG Steps[ 238 ] Max Score[ 150 ]\n",
            "-- Partidas[ 1000 ] Avg.Puntos[ 28 ]  AVG Steps[ 266 ] Max Score[ 210 ]\n",
            "-- Partidas[ 1500 ] Avg.Puntos[ 27 ]  AVG Steps[ 264 ] Max Score[ 210 ]\n",
            "-- Partidas[ 2000 ] Avg.Puntos[ 29 ]  AVG Steps[ 269 ] Max Score[ 390 ]\n",
            "-- Partidas[ 2500 ] Avg.Puntos[ 29 ]  AVG Steps[ 271 ] Max Score[ 390 ]\n",
            "Partidas[ 2999 ] Avg.Puntos[ 30 ] Max score[ 390 ] en partida[ 1893 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBZtPwOfvW0s"
      },
      "source": [
        "#Resultado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "2YBi4LbwsOoE",
        "outputId": "21edb3f0-d76d-467a-a5ba-232ef338421f"
      },
      "source": [
        "learner2 = PongAgent(game, policy=learner.get_policy())\n",
        "learner2.ratio_explotacion = 1.0  # con esto quitamos las elecciones aleatorias al jugar\n",
        "player = play(rounds=1, learner=learner2, game=game, animate=True)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fwqalmalsy9l"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}